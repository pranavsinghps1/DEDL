{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Using Autoencoder Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import itertools\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch import nn, optim\n",
    "import time\n",
    "import copy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "import timm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.listdir('./Myositis Images/CD27 Panel-- Component')\n",
    "label_file = os.listdir('./Myositis Images/Labels/CD27 cell labels')\n",
    "label_file.remove('Bounding Rectangle')\n",
    "label_file.remove('Mask Labels')\n",
    "mask_label_file = os.listdir('./Myositis Images/Labels/CD27 cell labels/Mask Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = set([_[:-9] for _ in data_file]).intersection(set([_[:-11] for _ in label_file])).intersection(set([_[:-17] for _ in mask_label_file]))\n",
    "print(len(selected_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_IMAGE_MEAN = (0.485, 0.456, 0.406)\n",
    "DATASET_IMAGE_STD = (0.229, 0.224, 0.225)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(3),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD), \n",
    "    ])\n",
    "transform_val=transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
    "\n",
    "transform_test=transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To keep the results comparable we are using \n",
    "the same splits as Van Buren et al (https://www.sciencedirect.com/science/article/pii/S0022175922000205), \n",
    "and code at: https://github.com/tniewold/Artificial-Intelligence-and-Deep-Learning-to-Map-Immune-Cell-Types-in-Inflamed-Human-Tissue\n",
    "\"\"\"\n",
    "\n",
    "train_list = [[(_ + '_data_' + str(idx) + '.npy',  _ + '_mask_' + str(idx) + '.npy') for idx in range(12)] \n",
    "              for _ in selected_data if _[:13] in ['121919_Myo089', '121919_Myo253', '121919_Myo368']]\n",
    "validation_list = [[(_ + '_data_' + str(idx) + '.npy', _ + '_mask_' + str(idx) + '.npy') for idx in range(12)] \n",
    "                   for _ in selected_data if _[:13] in ['121919_Myo208', '121919_Myo388']]\n",
    "test_list = [[(_ + '_data_' + str(idx) + '.npy', _ + '_mask_' + str(idx) + '.npy') for idx in range(12)] \n",
    "             for _ in selected_data if _[:13] in ['121919_Myo231', '121919_Myo511']]\n",
    "train_list = list(itertools.chain(*train_list))\n",
    "validation_list = list(itertools.chain(*validation_list))\n",
    "test_list = list(itertools.chain(*test_list))\n",
    "print('train data: {}'.format(len(train_list)))\n",
    "print('validation data: {}'.format(len(validation_list)))\n",
    "print('test data: {}'.format(len(test_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = np.load('./New data/New Image Tile/image/' + (self.file_list[idx][0]),allow_pickle=True)\n",
    "        bdry = np.load('./New data/New Image Tile/labels/' + (self.file_list[idx][1]),allow_pickle=True)\n",
    "        mask_label = np.load('./New data/New Image Tile/labels/' + (self.file_list[idx][1]),allow_pickle=True)\n",
    "        mask_label = mask_label / 255\n",
    "        \n",
    "        \n",
    "        \n",
    "        inputs = torch.from_numpy(inputs).unsqueeze(0)\n",
    "        bdry = torch.from_numpy(bdry).unsqueeze(0)\n",
    "        mask_label = torch.from_numpy(mask_label).unsqueeze(0)\n",
    "        label = torch.max(bdry * 2, mask_label).long().squeeze()\n",
    "\n",
    "        if self.transform:\n",
    "            inputs = self.transform(inputs)\n",
    "            mask_label = self.transform(mask_label)\n",
    "\n",
    "        return (inputs, mask_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = {}\n",
    "dataloader['train'] = DataLoader(CustomDataset(train_list,transform=transform_train), batch_size=16, shuffle=True, num_workers=8, drop_last=False)\n",
    "dataloader['validation'] = DataLoader(CustomDataset(validation_list,transform=transform_val), batch_size=16, shuffle=False, num_workers=8, drop_last=False)\n",
    "dataloader['test'] = DataLoader(CustomDataset(test_list,transform=transform_test), batch_size=16, shuffle=False, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasize = {'train': len(train_list), 'validation': len(validation_list), 'test': len(test_list)}\n",
    "datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=480, out_features=15360) \n",
    "        self.encmid = nn.Linear(in_features=15360, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=16)\n",
    "\n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=16, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=480) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.encmid(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        x = F.relu(self.enc5(x))\n",
    "\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc=[]\n",
    "train_acc_mask=[]\n",
    "train_acc_boundary=[]\n",
    "train_acc_bg=[]\n",
    "val_acc=[]\n",
    "val_acc_mask=[]\n",
    "val_acc_boundary=[]\n",
    "val_acc_bg=[]\n",
    "iou_q_val=[]\n",
    "iou_q_t=[]\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler,encoder_name, autoencoder,criterion_ae,optimizer_ae,num_epochs=50, maximum_patient=5):\n",
    "    since = time.time()\n",
    "    best_iou = 0.0\n",
    "    best_loss = 0.0\n",
    "    total_loss=0\n",
    "    prev=math.inf\n",
    "    best=0\n",
    "    counter=0\n",
    "    last_val=0\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for inputs, mask in dataloader['train']:\n",
    "            model.train()\n",
    "            ae.train()\n",
    "            inputs = inputs.to(device)\n",
    "            mask = mask.squeeze().to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs_ae=ae(outputs)\n",
    "            \n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            loss1 = criterion(outputs, mask.long())\n",
    "            loss2 = criterion_ae(outputs_ae, mask.long())\n",
    "            loss=loss1+loss2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer_ae.step()\n",
    "            optimizer_ae.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            total_loss+=loss.item()\n",
    "        avg_loss = total_loss/len(dataloader['train'])\n",
    "        tp1, fp1, fn1, tn1 = smp.metrics.get_stats(pred==1, mask==1, mode='multilabel', threshold=0.5)\n",
    "        tp2, fp2, fn2, tn2 = smp.metrics.get_stats(pred==0, mask==0, mode='multilabel', threshold=0.5)\n",
    "        mask_accuracy = smp.metrics.accuracy(tp1, fp1, fn1, tn1, reduction=\"macro\")\n",
    "        print(\"Mask Accuracy:\", mask_accuracy)\n",
    "        bg_accuracy = smp.metrics.accuracy(tp2, fp2, fn2, tn2, reduction=\"macro\")\n",
    "        print(\"Background Accuracy:\", bg_accuracy)\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(pred, mask.long(), mode='multilabel', threshold=0.5)\n",
    "        iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
    "        print(\"overall Acc:\",accuracy)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        #print('{} Loss: {:.4f}  Mask Acc: {:.4f} Background Acc: {:.4f} Overall Acc: {:.4f}'.format(phase, epoch_loss, epoch_mask, epoch_bkgd, epoch_acc))\n",
    "        print(\"Appending to Train List\")\n",
    "        train_acc.append(accuracy)\n",
    "        train_acc_mask.append(mask_accuracy)\n",
    "        #train_acc_boundary.append(epoch_bdry)\n",
    "        train_acc_bg.append(bg_accuracy)\n",
    "        print('IoU:',iou_score)\n",
    "        epoch_iou=iou_score\n",
    "        iou_q_t.append(iou_score)\n",
    "        if epoch_iou > best:\n",
    "            #Validating\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                total_loss=0\n",
    "                print('Validation')\n",
    "                print('-' * 20)\n",
    "                for inputs, mask in dataloader['validation']:\n",
    "                    inputs = inputs.to(device)\n",
    "                    mask = mask.squeeze().to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    pred = torch.argmax(outputs, dim=1)\n",
    "                    loss = criterion(outputs, mask.long())\n",
    "                    total_loss+=loss.item()\n",
    "                avg_loss=total_loss/len(dataloader['validation'])\n",
    "            \n",
    "                tp1, fp1, fn1, tn1 = smp.metrics.get_stats(pred==1, mask==1, mode='multilabel', threshold=0.5)\n",
    "                tp2, fp2, fn2, tn2 = smp.metrics.get_stats(pred==0, mask==0, mode='multilabel', threshold=0.5)\n",
    "                mask_accuracy = smp.metrics.accuracy(tp1, fp1, fn1, tn1, reduction=\"macro\")\n",
    "                print(\"Mask Accuracy:\", mask_accuracy)\n",
    "                bg_accuracy = smp.metrics.accuracy(tp2, fp2, fn2, tn2, reduction=\"macro\")\n",
    "                print(\"Background Accuracy:\", bg_accuracy)\n",
    "                tp, fp, fn, tn = smp.metrics.get_stats(pred, mask.long(), mode='multilabel', threshold=0.5)\n",
    "                iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "                accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
    "                print(\"overall Acc:\",accuracy)\n",
    "                print(\"Validation IoU:\",iou_score)\n",
    "                if iou_score > last_val:\n",
    "                    last_val=iou_score\n",
    "                    print(\"Saving Model!\")\n",
    "                    torch.save(model, \n",
    "                               './Saved_models/Unet-ae-{}-scse-depth3-imgnet-es.pt'.format(encoder_name))\n",
    "                \n",
    "                \n",
    "            if avg_loss > prev:\n",
    "                counter+=1\n",
    "            else:\n",
    "                counter = 0\n",
    "                \n",
    "                \n",
    "            prev=avg_loss\n",
    "            \n",
    "            if counter > 5:\n",
    "                print(\"ES!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Unet with timm-efficientnet-b0 backbone\n",
    "encoder_name='timm-efficientnet-b0'\n",
    "model = smp.Unet(encoder_name=encoder_name,decoder_attention_type='scse',encoder_weights='imagenet',in_channels=1, classes=2,encoder_depth=3,decoder_channels=(256, 128, 64))\n",
    "ae = Autoencoder()\n",
    "ae = ae.to(device)\n",
    "criterion_ae = nn.MSELoss()\n",
    "optimizer_ae = optim.Adam(ae.parameters(), lr=1e-3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum', weight=torch.tensor([0.1479139275021023,0.8520860724978977]).to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=3.6e-04, weight_decay=1e-05)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 50, eta_min= 3.4e-04, last_epoch=- 1)\n",
    "train_model(model, criterion, optimizer, scheduler,encoder_name,autoencoder = ae,criterion_ae=criterion_ae,optimizer_ae=optimizer_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./Saved_models/Unet-ae-timm-efficientnet-b0-scse-depth3-imgnet-es.pt')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "tp_total=0\n",
    "fp_total=0\n",
    "fn_total=0\n",
    "tn_total=0\n",
    "for inputs, mask in dataloader['test']:\n",
    "    inputs=inputs.to(device)\n",
    "    mask=mask.to(device)\n",
    "    outputs = model(inputs)\n",
    "    model.to(device)\n",
    "    mask = mask.squeeze().to(device)\n",
    "    pred = torch.argmax(outputs, dim=1)\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(pred, mask.long(), mode='multilabel', threshold=0.5)\n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
    "    tp_total+=tp\n",
    "    fp_total+=fp\n",
    "    fn_total+=fn\n",
    "    tn_total+=tn\n",
    "print('Overall Scores:')\n",
    "iou_score = smp.metrics.iou_score(tp_total, fp_total, fn_total, tn_total, reduction=\"micro\")\n",
    "accuracy = smp.metrics.accuracy(tp_total, fp_total, fn_total, tn_total, reduction=\"macro\")\n",
    "print(\"Pixel Acc:\",accuracy)\n",
    "print(\"IoU:\",iou_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}