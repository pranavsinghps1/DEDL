{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision import transforms as tsfm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import seed_everything\n",
    "from torchcontrib.optim import SWA\n",
    "from torchmetrics import Metric\n",
    "\"\"\"\n",
    "Some parts of the code are based on https://www.kaggle.com/code/qkn123/efficientb4-inference\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF = pd.read_csv('./New data/Metadata/test_list.csv')\n",
    "all_imgtest_names: list = TEST_DF[\"file\"].values.tolist()\n",
    "all_imgtest_labels: list = TEST_DF[\"label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # data path\n",
    "    train_csv_path = './New data/Metadata/train_list.csv'\n",
    "    #train_list.csv only has train split\n",
    "    train_imgs_dir = './New data/backup/Classification_images/'\n",
    "    # label info\n",
    "    label_num2str = {0: 'b',\n",
    "                     1: 'tfh',\n",
    "                     2: 'tfh217',\n",
    "                     3: 'tfhl',\n",
    "                     4: 'other'}\n",
    "    label_str2num = {'b': 0,\n",
    "                     'tfh': 1,\n",
    "                     'tfh217': 2,\n",
    "                     'tfhl': 3,\n",
    "                     'other': 4}\n",
    "    fl_alpha = 1.0  # alpha of focal_loss\n",
    "    fl_gamma = 2.0  # gamma of focal_loss\n",
    "    cls_weight = [0.9475164011246484, 0.4934395501405811, 0.5029053420805999, 0.2, 1.0]\n",
    "    cnn_name='resnet50'\n",
    "    vit_name='vit_base_patch16_384'\n",
    "    seed = 77\n",
    "    num_classes = 5\n",
    "    batch_size = 16\n",
    "    t_max = 16\n",
    "    lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    n_fold = 6\n",
    "    num_workers = 8\n",
    "    accum_grad_batch = 1\n",
    "    early_stop_delta = 1e-7\n",
    "    gpu_idx = 0\n",
    "    device = torch.device(f'cuda:{gpu_idx}' if torch.cuda.is_available() else 'cpu')\n",
    "    gpu_list = [gpu_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed_everything(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define train & valid image transformation\n",
    "\"\"\"\n",
    "DATASET_IMAGE_MEAN = (0.485, 0.456, 0.406)\n",
    "DATASET_IMAGE_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_transform = tsfm.Compose([tsfm.Resize((384,384)),\n",
    "                                tsfm.RandomApply([tsfm.ColorJitter(0.2, 0.2, 0.2),tsfm.RandomPerspective(distortion_scale=0.2),], p=0.3),\n",
    "                                tsfm.RandomApply([tsfm.ColorJitter(0.2, 0.2, 0.2),tsfm.RandomAffine(degrees=10),], p=0.3),\n",
    "                                tsfm.RandomVerticalFlip(p=0.3),\n",
    "                                tsfm.RandomHorizontalFlip(p=0.3),\n",
    "                                tsfm.ToTensor(),\n",
    "                                tsfm.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD), ])\n",
    "\n",
    "valid_transform = tsfm.Compose([tsfm.Resize((384,384)),\n",
    "                                tsfm.ToTensor(),\n",
    "                                tsfm.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD), ])\n",
    "\n",
    "test_transform = tsfm.Compose([tsfm.Resize((384,384)),\n",
    "                                tsfm.ToTensor(),\n",
    "                                tsfm.Normalize(DATASET_IMAGE_MEAN, DATASET_IMAGE_STD), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define dataset class\n",
    "\"\"\"\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, cfg, img_names: list, labels: list, transform=None):\n",
    "        self.img_dir = cfg.train_imgs_dir\n",
    "        self.img_names = img_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx]+'.jpg')\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_ts = self.transform(img)\n",
    "        label_ts = self.labels[idx]\n",
    "        return img_ts, label_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Focal-Loss\n",
    "\"\"\"\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    The focal loss for fighting against class-imbalance\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = 1e-12  # prevent training from Nan-loss error\n",
    "        self.cls_weights = torch.tensor([CFG.cls_weight],dtype=torch.float, requires_grad=False, device=CFG.device)\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        \"\"\"\n",
    "        logits & target should be tensors with shape [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(logits)\n",
    "        one_subtract_probs = 1.0 - probs\n",
    "        # add epsilon\n",
    "        probs_new = probs + self.epsilon\n",
    "        one_subtract_probs_new = one_subtract_probs + self.epsilon\n",
    "        # calculate focal loss\n",
    "        log_pt = target * torch.log(probs_new) + (1.0 - target) * torch.log(one_subtract_probs_new)\n",
    "        pt = torch.exp(log_pt)\n",
    "        focal_loss = -1.0 * (self.alpha * (1 - pt) ** self.gamma) * log_pt\n",
    "        focal_loss = focal_loss * self.cls_weights\n",
    "        return torch.mean(focal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define F1 score metric\n",
    "\"\"\"\n",
    "class MyF1Score(Metric):\n",
    "    def __init__(self, cfg, threshold: float = 0.5, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.cfg = cfg\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"tp\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"fp\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"fn\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        assert preds.shape == target.shape\n",
    "        preds_str_batch = self.num_to_str(torch.sigmoid(preds))\n",
    "        target_str_batch = self.num_to_str(target)\n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        for pred_str_list, target_str_list in zip(preds_str_batch, target_str_batch):\n",
    "            for pred_str in pred_str_list:\n",
    "                if pred_str in target_str_list:\n",
    "                    tp += 1\n",
    "                if pred_str not in target_str_list:\n",
    "                    fp += 1\n",
    "\n",
    "            for target_str in target_str_list:\n",
    "                if target_str not in pred_str_list:\n",
    "                    fn += 1\n",
    "        self.tp += tp\n",
    "        self.fp += fp\n",
    "        self.fn += fn\n",
    "\n",
    "    def compute(self):\n",
    "        #f1 = 2.0 * self.tp / (2.0 * self.tp + self.fn + self.fp)\n",
    "        rec = self.tp/(self.tp + self.fn)\n",
    "        return rec\n",
    "    \n",
    "    def num_to_str(self, ts: torch.Tensor) -> list:\n",
    "        batch_bool_list = (ts > self.threshold).detach().cpu().numpy().tolist()\n",
    "        batch_str_list = []\n",
    "        for one_sample_bool in batch_bool_list:\n",
    "            lb_str_list = [self.cfg.label_num2str[lb_idx] for lb_idx, bool_val in enumerate(one_sample_bool) if bool_val]\n",
    "            batch_str_list.append(lb_str_list)\n",
    "        return batch_str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_labels_ts = []\n",
    "for tmp_lb in all_imgtest_labels:\n",
    "    tmp_label = torch.zeros([CFG.num_classes], dtype=torch.float)\n",
    "    j = tmp_lb[1:-1]\n",
    "    for a in j:\n",
    "        if a != ',' and  a !=' ':\n",
    "            k=int(a)\n",
    "            tmp_label[k] = 1.0\n",
    "    all_img_labels_ts.append(tmp_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "cfg=CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ps4364/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Dataset(CFG, all_imgtest_names,all_img_labels_ts, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn=torch.load('./Saved_models/resnet101-5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.0000e-04.\n",
      "{'train_loss': tensor(0.0403, device='cuda:0'), 'Recall': tensor(0.8132), 'lr': 0.0003}\n"
     ]
    }
   ],
   "source": [
    "criterion = FocalLoss(cfg.fl_alpha, cfg.fl_gamma)\n",
    "metric = MyF1Score(cfg)\n",
    "val_metric=MyF1Score(cfg)\n",
    "optimizer = torch.optim.Adam(model_cnn.parameters(), lr = 3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=cfg.t_max,eta_min=cfg.min_lr,verbose=True)\n",
    "model_cnn.eval()\n",
    "with torch.no_grad():\n",
    "    for images,label in test_loader:\n",
    "        images = images.to(device)\n",
    "        label = label.to(device)\n",
    "        model_cnn.to(device)\n",
    "        pred_ts=model_cnn(images)\n",
    "        loss = criterion(pred_ts, label)\n",
    "        score = metric(pred_ts, label)\n",
    "test_score=metric.compute()\n",
    "logs = {'train_loss': loss, 'Recall': test_score, 'lr': optimizer.param_groups[0]['lr']}\n",
    "print(logs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
